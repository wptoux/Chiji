{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import io\n",
    "import cv2\n",
    "import requests\n",
    "import bs4\n",
    "import jieba\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def capture_img():\n",
    "    subprocess.call('.\\\\adb\\\\adb shell /system/bin/screencap -p /sdcard/screenshot.png')\n",
    "    time.sleep(0.1)\n",
    "    subprocess.call('.\\\\adb\\\\adb pull /sdcard/screenshot.png %s' % './tmp/screenshot.png')\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    return cv2.imread('./tmp/screenshot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run aip_key.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aip import AipOcr\n",
    "\n",
    "client = AipOcr(APP_ID, API_KEY, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_in_region(aip_rst, region):\n",
    "    s = ''\n",
    "    if 'words_result' in aip_rst:\n",
    "        words = []\n",
    "        for p in aip_rst['words_result']:\n",
    "            loc = p['location']\n",
    "            if loc['top'] > region[0] and loc['top'] + loc['height'] < region[1] \\\n",
    "                and loc['left'] > region[2] and loc['left'] + loc['width'] < region[3]:\n",
    "                if loc['left'] < 1080 / 2: # only get words that starts from left\n",
    "                    words.append(p['words'])\n",
    "        s = ''.join(words)\n",
    "        \n",
    "    if s != '':\n",
    "        # remove heading, like 1. A. B.\n",
    "        if re.match(r\"^A|B|C|\\d+\\.|,|。|，\", s) != None: \n",
    "            ss = re.split(r\"\\.|,|。|，\",s)\n",
    "            if len(ss) > 1:\n",
    "                s = ''.join(ss[1:])\n",
    "            \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ocr(im, regions):\n",
    "    _, byte_arr = cv2.imencode('.jpg', im, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "    aip_rst = client.general(byte_arr.tobytes())\n",
    "    return [get_text_in_region(aip_rst, region) for region in regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def go_search(s, engine='google'):\n",
    "    if engine == 'google':\n",
    "        os.system('start www.google.com/search?q=%s' % s)\n",
    "    elif engine == 'baidu':\n",
    "        os.system('start www.baidu.com/s?wd=%s' % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(question):\n",
    "    rst = requests.get('http://www.baidu.com/s?wd=%s&rn=50' % question)\n",
    "    rst.encoding = 'utf-8'\n",
    "    search_rst = rst.text\n",
    "    \n",
    "    soup = bs4.BeautifulSoup(search_rst, 'html.parser')\n",
    "    rst = soup.select('div#content_left')[0]\n",
    "    return rst.text\n",
    "\n",
    "def search_advanced(question_words, opt_words):\n",
    "    '''\n",
    "    Advanced search\n",
    "    question_words: list of words of the question\n",
    "    opt_words: list of list of words of the options\n",
    "    '''\n",
    "    all_opt_words = []\n",
    "    \n",
    "    for words in opt_words:\n",
    "        all_opt_words += words\n",
    "        \n",
    "    rst = requests.get('http://www.baidu.com/s?q1=%s&q2=&q3=%s&q4=&rn=50' % (\n",
    "        '+'.join(question_words),\n",
    "        '+'.join(all_opt_words)))\n",
    "    print('http://www.baidu.com/s?q1=%s&q2=&q3=%s&q4=&rn=50' % (\n",
    "        '+'.join(question_words),\n",
    "        '+'.join(all_opt_words)))\n",
    "    rst.encoding = 'utf-8'\n",
    "    search_rst = rst.text\n",
    "    \n",
    "    soup = bs4.BeautifulSoup(search_rst, 'html.parser')\n",
    "    rst = soup.select('div#content_left')[0]\n",
    "    return rst.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "extend(...)\n",
      "    L.extend(iterable) -> None -- extend list by appending elements from the iterable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(list.extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def occur_count(s,words):\n",
    "    n = 0\n",
    "    for word in words:\n",
    "        n += len(re.findall(word, s))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywords(question, opt_a, opt_b, opt_c):\n",
    "    quest_words = jieba.analyse.extract_tags(question, allowPOS=['n','nr','ns','nt','nz','nl','ng'])\n",
    "    opt_words = jieba.analyse.extract_tags(' '.join([opt_a,opt_b,opt_c]), allowPOS=['n','nr','ns','nt','nz','nl','ng'])\n",
    "    words = quest_words + opt_words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_question(question, opt_a, opt_b, opt_c):\n",
    "    with open('questions.txt','a+') as f:\n",
    "        f.write(','.join([question, opt_a, opt_b, opt_c]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def search_ans_from_pic(im):\n",
    "    print('Parsing pic...')\n",
    "    \n",
    "    question, opt_a, opt_b, opt_c = ocr(im,\n",
    "                   [(300,600,0,1080),\n",
    "                   (655,815,0,1080),\n",
    "                   (845,1005,0,1080),\n",
    "                   (1035,1200,0,1080)])\n",
    "\n",
    "    if question != '':\n",
    "        quest_words = jieba.analyse.extract_tags(question)\n",
    "\n",
    "        opts = [opt_a, opt_b, opt_c]\n",
    "        opt_words = []\n",
    "        for opt in opts:\n",
    "#             opt_words.append(list(map(lambda p:p.word, filter(lambda p:p.flag.startswith('n'), \n",
    "#                                                  jieba.posseg.cut(opt)))))\n",
    "            opt_words.append(jieba.analyse.extract_tags(opt))\n",
    "\n",
    "#         rst = search(question)\n",
    "#         time.sleep(0.1)\n",
    "#         rst += search('%20'.join(quest_words))\n",
    "        rst = search_advanced(quest_words, opt_words)\n",
    "\n",
    "        opt_cnt = []\n",
    "        for i, opt_w in enumerate(opt_words):\n",
    "            opt_cnt.append(occur_count(rst, opt_w))\n",
    "\n",
    "\n",
    "        ans = [('A',opt_a,opt_cnt[0]),\n",
    "              ('B',opt_b,opt_cnt[1]),\n",
    "              ('C',opt_c,opt_cnt[2])]\n",
    "        \n",
    "        \n",
    "\n",
    "        print('question:', question)\n",
    "        for p in sorted(ans, key=lambda p:p[2], reverse=True):\n",
    "            print(p)\n",
    "\n",
    "#         go_search(question)\n",
    "\n",
    "        dump_question(question, opt_a, opt_b, opt_c)\n",
    "\n",
    "    else:\n",
    "        print('No question found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread('./tmp/screenshot.png')\n",
    "im = im[:1200,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing pic...\n",
      "http://www.baidu.com/s?q1=海沟+最深+哪个+以下&q2=&q3=马里亚纳+海沟+波多黎各+海沟+海沟+菲律宾&q4=&rn=50\n",
      "question: 以下哪个海沟最深?\n",
      "('A', '马里亚纳海沟', 138)\n",
      "('C', '菲律宾海沟', 135)\n",
      "('B', '波多黎各海沟', 119)\n"
     ]
    }
   ],
   "source": [
    "search_ans_from_pic(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing pic...\n",
      "question: 茅台酒原产于我国哪里?\n",
      "('B', '山西省', 0)\n",
      "('C', '河南省', 0)\n",
      "('A', '贵州省', 4)\n",
      "\n",
      "Parsing pic...\n",
      "question: 我们常说“人心齐什么移\"?\n",
      "('A', '黄山', 0)\n",
      "('C', '华山', 0)\n",
      "('B', '泰山', 25)\n",
      "\n",
      "Parsing pic...\n",
      "question: 我和西瓜视频独家出品的脱口秀节目名称是?\n",
      "('B', '《一郭烩》', 0)\n",
      "('C', '《郭的秀》', 0)\n",
      "('A', '《一郭汇》', 14)\n",
      "\n",
      "Parsing pic...\n",
      "question: 《哈利波特》的作者JK罗琳是哪国人?\n",
      "('B', '美国', 0)\n",
      "('C', '澳大利亚', 0)\n",
      "('A', '英国', 10)\n",
      "\n",
      "Parsing pic...\n",
      "question: 歌歌曲《十年》的原唱是哪位歌手?\n",
      "('A', '林俊杰', 0)\n",
      "('B', '周杰伦', 0)\n",
      "('C', '陈奕迅', 13)\n",
      "\n",
      "Parsing pic...\n",
      "question: 下列哪一部是鲁迅创作的文学作品?\n",
      "('B', '《我的大学》', 0)\n",
      "('C', '《家》', 0)\n",
      "('A', '《祝福》', 1)\n",
      "\n",
      "Parsing pic...\n",
      "question: “2x-1=0”这是什么方程?\n",
      "('A', '二元一次方程', 1)\n",
      "('B', '一元二次方程', 1)\n",
      "('C', '元一次方程', 1)\n",
      "\n",
      "Parsing pic...\n",
      "question: 现在以下哪一艺术作品没有馆藏于巴黎卢浮宫?\n",
      "('A', '《蒙娜丽莎》', 3)\n",
      "('B', '《断臂的维纳斯》', 3)\n",
      "('C', '《最后的晚餐》', 4)\n",
      "\n",
      "Parsing pic...\n",
      "question: 标准大气压下下列哪种金属的熔点最高?\n",
      "('A', '锡', 0)\n",
      "('B', '铁', 0)\n",
      "('C', '金', 0)\n",
      ".\n",
      "Parsing pic...\n",
      "question: 我国在哪一年成功研制出第一颗原子弹?\n",
      "('B', '1968年', 0)\n",
      "('C', '1970年', 0)\n",
      "('A', '1964年', 8)\n",
      "\n",
      "Parsing pic...\n",
      "question: 以下哪个海沟最深?\n",
      "('B', '波多黎各海沟', 30)\n",
      "('C', '菲律宾海沟', 30)\n",
      "('A', '马里亚纳海沟', 43)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ipt = input()\n",
    "    if ipt == 'q':\n",
    "        break\n",
    "    else:\n",
    "        im = capture_img()\n",
    "        search_ans_from_pic(im[:1200,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
